{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc184dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb2ff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\anjal\\Downloads\\IMDB Dataset.csv\\IMDB Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4423dd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e9ec11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc45a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random_seed = 42\n",
    "sample_size = 20000\n",
    "\n",
    "# Randomly sample 20,000 rows from the original dataset\n",
    "data = df.sample(n=sample_size, random_state=random_seed)\n",
    "\n",
    "# Now 'sampled_df' contains 20,000 random samples from your original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4a4512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000,) (14000,)\n",
      "(6000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset  \n",
    "#train dataset\n",
    "train_reviews=data.review[:14000]\n",
    "train_sentiments=data.sentiment[:14000]\n",
    "#test dataset\n",
    "test_reviews=data.review[14000:]\n",
    "test_sentiments=data.sentiment[14000:]\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "print(test_reviews.shape,test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f09dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ea15d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#Removing the html strips\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5895ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for removing special characters\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49471819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the text\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae01fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'against', 'be', 's', 'had', 'did', 'if', 'ain', 'at', 'him', 'nor', 'an', 'weren', 'too', 'down', 'off', 'once', 'herself', \"didn't\", 'shan', 'such', 'ours', 'than', 'me', 'which', 've', 'who', 'her', 'itself', 'were', 'has', 'from', 'doesn', 'all', 'have', 'his', 'over', 'then', 'are', \"won't\", \"you're\", 'don', 'its', \"wouldn't\", \"hadn't\", 'and', 'haven', 'themselves', 'their', 'about', 'with', 'further', 'hadn', 'hasn', \"mightn't\", 'couldn', 'y', 'my', 'in', 'been', 'most', 'same', 'between', 'of', \"hasn't\", 'the', 'why', 'after', 'how', 'here', 'd', 'isn', 'not', 'these', 'is', \"you'll\", 'm', 'a', \"should've\", 'what', 'before', 'but', 'am', 'do', 'to', 'needn', 'into', \"weren't\", 'above', 'yourself', 'hers', 'by', 'when', \"shan't\", 'myself', \"isn't\", 'because', 'until', 'yourselves', \"she's\", 'other', 'up', 'just', 'can', 'wouldn', 'below', 'own', 'that', 'yours', 'on', \"aren't\", 'any', 'we', 'both', 'there', 'now', 'through', 'ma', 'some', 'shouldn', 'each', 'having', \"you've\", 'll', 'himself', 'your', 'it', 'you', \"doesn't\", 'won', 'while', \"that'll\", 'so', 'or', 'mustn', 'this', 'theirs', 'he', 'whom', 'under', 'ourselves', 'our', 'didn', \"mustn't\", \"couldn't\", 'mightn', 'they', 'during', \"shouldn't\", 'for', \"it's\", 'few', 'being', 'out', 'i', 'only', 'aren', 'she', 'doing', 'will', 'again', \"needn't\", 'should', 'o', 'more', 'as', \"you'd\", 'was', 'does', 'wasn', 're', 'them', 'those', \"wasn't\", 'where', \"don't\", \"haven't\", 't', 'very', 'no'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#set stopwords to english\n",
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ba2be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realli like thi summerslam due look arena curtain look overal wa interest reason anyway thi could one best summerslam ever wwf didnt lex luger main event yokozuna time wa ok huge fat man vs strong man im glad time chang wa terribl main event like everi match luger terribl match card razor ramon vs ted dibias steiner brother vs heavenli bodi shawn michael vs curt hene thi wa event shawn name hi big monster bodi guard diesel ir vs 123 kid bret hart first take doink take jerri lawler stuff hart lawler wa alway veri interest ludvig borga destroy marti jannetti undertak took giant gonzalez anoth terribl match smoke gunn tatanka took bam bam bigelow headshrink yokozuna defend world titl lex luger thi match wa bore ha terribl end howev deserv 810\n"
     ]
    }
   ],
   "source": [
    "# normalized train reviews\n",
    "norm_train_reviews = data.review[:14000]\n",
    "first_review = norm_train_reviews.iloc[0]\n",
    "print(first_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f1e71fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'almost made fool wa go start thi review say thi movi remind billi elliot look resum screenwrit lee hall onli find wa guy wrote billi elliot mr hall make fool bit cruel becaus lee ha someth aspir screenwrit britain dont ha hi foot door ha previous written success british movi award made money box offic doe next give audienc young jimmi spud live kitchen sink estat bulli school one love onli thing keep go ha aspir ballet dancer actual ha aspir angel consid hi household may well ballet dancer ha macho waster father think ballet dancer bunch poof hi granddad say ballet dancer tough ani man could meet rememb see bolshoi ballet yup ballet main talk point run british council estat day come think neither left wing polit seem sole preserv middl class gooder live nice big hous right away everyth thi set feel ridicul fals anoth major critic thi film ha clue tri appeal often criticis channel 4 broadcast movi total inappropri time land time forgot 6 exampl show thi 2 onc theyv got spot consid stori involv polit ballet danc gawd hate lung cancer poverti way thi deem suitabl famili audienc sinc main protagonist 11 year old child featur angel ballet dancer dont blame seem obsess subject wa need refer much intellig adult audienc either cours lee hall told script develop stage produc write stori featur schoolboy angel flatli refus say want write theme stori apologis throughout movi get feel onc film wa complet wa go market exact audienc enjoy billi elliot'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalized test reviews\n",
    "norm_test_reviews=data.review[14000:]\n",
    "norm_test_reviews[5005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db1622de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (14000, 2470308)\n",
      "BOW_cv_test: (6000, 2470308)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "cv_test_reviews=cv.transform(norm_test_reviews)\n",
    "\n",
    "print('BOW_cv_train:',cv_train_reviews.shape)\n",
    "print('BOW_cv_test:',cv_test_reviews.shape)\n",
    "#vocab=cv.get_feature_names()-toget feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09203bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (14000, 2470308)\n",
      "Tfidf_test: (6000, 2470308)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Tfidf vectorizer\n",
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(norm_test_reviews)\n",
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e0ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "#labeling the sentient data\n",
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(data['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ef69ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#Spliting the sentiment data\n",
    "train_sentiments=sentiment_data[:14000]\n",
    "test_sentiments=sentiment_data[14000:]\n",
    "print(train_sentiments)\n",
    "print(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d744469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#training the model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
    "print(lr_bow)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c561b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n",
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict=lr.predict(cv_test_reviews)\n",
    "print(lr_bow_predict)\n",
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=lr.predict(tv_test_reviews)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2f64709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_score : 0.7258333333333333\n",
      "lr_tfidf_score : 0.7121666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#Accuracy score for bag of words\n",
    "lr_bow_score=accuracy_score(test_sentiments,lr_bow_predict)\n",
    "print(\"lr_bow_score :\",lr_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5ffc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.75      0.69      0.72      3043\n",
      "    Negative       0.71      0.76      0.73      2957\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.73      0.73      0.73      6000\n",
      "weighted avg       0.73      0.73      0.73      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.79      0.59      0.68      3043\n",
      "    Negative       0.67      0.84      0.74      2957\n",
      "\n",
      "    accuracy                           0.71      6000\n",
      "   macro avg       0.73      0.71      0.71      6000\n",
      "weighted avg       0.73      0.71      0.71      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#Classification report for bag of words \n",
    "lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n",
    "print(lr_bow_report)\n",
    "\n",
    "#Classification report for tfidf features\n",
    "lr_tfidf_report=classification_report(test_sentiments,lr_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee9d744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2246  711]\n",
      " [ 934 2109]]\n",
      "[[2470  487]\n",
      " [1240 1803]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,lr_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19aff6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=500, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#training the linear svm\n",
    "svm=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
    "#fitting the svm for bag of words\n",
    "svm_bow=svm.fit(cv_train_reviews,train_sentiments)\n",
    "print(svm_bow)\n",
    "#fitting the svm for tfidf features\n",
    "svm_tfidf=svm.fit(tv_train_reviews,train_sentiments)\n",
    "print(svm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3adc2e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "svm_bow_predict=svm.predict(cv_test_reviews)\n",
    "print(svm_bow_predict)\n",
    "#Predicting the model for tfidf features\n",
    "svm_tfidf_predict=svm.predict(tv_test_reviews)\n",
    "print(svm_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a6e227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_bow_score : 0.618\n",
      "svm_tfidf_score : 0.4975\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "svm_bow_score=accuracy_score(test_sentiments,svm_bow_predict)\n",
    "print(\"svm_bow_score :\",svm_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "svm_tfidf_score=accuracy_score(test_sentiments,svm_tfidf_predict)\n",
    "print(\"svm_tfidf_score :\",svm_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "401747e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.89      0.28      0.43      3043\n",
      "    Negative       0.57      0.96      0.71      2957\n",
      "\n",
      "    accuracy                           0.62      6000\n",
      "   macro avg       0.73      0.62      0.57      6000\n",
      "weighted avg       0.73      0.62      0.57      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       1.00      0.01      0.02      3043\n",
      "    Negative       0.50      1.00      0.66      2957\n",
      "\n",
      "    accuracy                           0.50      6000\n",
      "   macro avg       0.75      0.50      0.34      6000\n",
      "weighted avg       0.75      0.50      0.34      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "svm_bow_report=classification_report(test_sentiments,svm_bow_predict,target_names=['Positive','Negative'])\n",
    "print(svm_bow_report)\n",
    "#Classification report for tfidf features\n",
    "svm_tfidf_report=classification_report(test_sentiments,svm_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(svm_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b90638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2848  109]\n",
      " [2183  860]]\n",
      "[[2957    0]\n",
      " [3015   28]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,svm_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,svm_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad39e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "MultinomialNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#training the model\n",
    "mnb=MultinomialNB()\n",
    "#fitting the svm for bag of words\n",
    "mnb_bow=mnb.fit(cv_train_reviews,train_sentiments)\n",
    "print(mnb_bow)\n",
    "#fitting the svm for tfidf features\n",
    "mnb_tfidf=mnb.fit(tv_train_reviews,train_sentiments)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ac41e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n",
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "mnb_bow_predict=mnb.predict(cv_test_reviews)\n",
    "print(mnb_bow_predict)\n",
    "#Predicting the model for tfidf features\n",
    "mnb_tfidf_predict=mnb.predict(tv_test_reviews)\n",
    "print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2f0c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_bow_score : 0.7276666666666667\n",
      "mnb_tfidf_score : 0.723\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "mnb_bow_score=accuracy_score(test_sentiments,mnb_bow_predict)\n",
    "print(\"mnb_bow_score :\",mnb_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n",
    "print(\"mnb_tfidf_score :\",mnb_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75fc78d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.74      0.72      0.73      3043\n",
      "    Negative       0.72      0.73      0.73      2957\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.73      0.73      0.73      6000\n",
      "weighted avg       0.73      0.73      0.73      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.75      0.68      0.71      3043\n",
      "    Negative       0.70      0.77      0.73      2957\n",
      "\n",
      "    accuracy                           0.72      6000\n",
      "   macro avg       0.73      0.72      0.72      6000\n",
      "weighted avg       0.73      0.72      0.72      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "mnb_bow_report=classification_report(test_sentiments,mnb_bow_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_bow_report)\n",
    "#Classification report for tfidf features\n",
    "mnb_tfidf_report=classification_report(test_sentiments,mnb_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d13204b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2173  784]\n",
      " [ 850 2193]]\n",
      "[[2279  678]\n",
      " [ 984 2059]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,mnb_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,mnb_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13e7e906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "KNeighborsClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "knn_bow_score : 0.5158333333333334\n",
      "knn_tfidf_score : 0.5066666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.51      0.97      0.67      3043\n",
      "    Negative       0.61      0.05      0.09      2957\n",
      "\n",
      "    accuracy                           0.52      6000\n",
      "   macro avg       0.56      0.51      0.38      6000\n",
      "weighted avg       0.56      0.52      0.38      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.51      0.96      0.66      3043\n",
      "    Negative       0.49      0.04      0.07      2957\n",
      "\n",
      "    accuracy                           0.51      6000\n",
      "   macro avg       0.50      0.50      0.37      6000\n",
      "weighted avg       0.50      0.51      0.37      6000\n",
      "\n",
      "[[ 142 2815]\n",
      " [  90 2953]]\n",
      "[[ 119 2838]\n",
      " [ 122 2921]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Training the model for K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fitting the model for Bag of Words\n",
    "knn_bow = knn.fit(cv_train_reviews, train_sentiments)\n",
    "print(knn_bow)\n",
    "# Fitting the model for tfidf features\n",
    "knn_tfidf = knn.fit(tv_train_reviews, train_sentiments)\n",
    "print(knn_tfidf)\n",
    "\n",
    "# Predicting the model for Bag of Words\n",
    "knn_bow_predict = knn.predict(cv_test_reviews)\n",
    "print(knn_bow_predict)\n",
    "# Predicting the model for tfidf features\n",
    "knn_tfidf_predict = knn.predict(tv_test_reviews)\n",
    "print(knn_tfidf_predict)\n",
    "\n",
    "# Accuracy score for Bag of Words\n",
    "knn_bow_score = accuracy_score(test_sentiments, knn_bow_predict)\n",
    "print(\"knn_bow_score :\", knn_bow_score)\n",
    "# Accuracy score for tfidf features\n",
    "knn_tfidf_score = accuracy_score(test_sentiments, knn_tfidf_predict)\n",
    "print(\"knn_tfidf_score :\", knn_tfidf_score)\n",
    "\n",
    "# Classification report for Bag of Words \n",
    "knn_bow_report = classification_report(test_sentiments, knn_bow_predict, target_names=['Positive', 'Negative'])\n",
    "print(knn_bow_report)\n",
    "# Classification report for tfidf features\n",
    "knn_tfidf_report = classification_report(test_sentiments, knn_tfidf_predict, target_names=['Positive', 'Negative'])\n",
    "print(knn_tfidf_report)\n",
    "\n",
    "# Confusion matrix for Bag of Words\n",
    "cm_bow = confusion_matrix(test_sentiments, knn_bow_predict, labels=[1, 0])\n",
    "print(cm_bow)\n",
    "# Confusion matrix for tfidf features\n",
    "cm_tfidf = confusion_matrix(test_sentiments, knn_tfidf_predict, labels=[1, 0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'data' is your sampled dataset\n",
    "sample_size = 20000\n",
    "random_seed = 42\n",
    "data = df.sample(n=sample_size, random_state=random_seed)\n",
    "\n",
    "# Tokenization and preprocessing functions\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Your preprocessing steps here\n",
    "    # ...\n",
    "\n",
    "    # Assuming 'text' is preprocessed\n",
    "    return text\n",
    "\n",
    "# Preprocess the entire dataset\n",
    "data['review'] = data['review'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = 14000\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "\n",
    "# Initialize and fit the TF-IDF vectorizer\n",
    "tv = TfidfVectorizer(min_df=0, max_df=1, use_idf=True, ngram_range=(1, 3))\n",
    "tv_train_reviews = tv.fit_transform(train_data['review'])\n",
    "tv_test_reviews = tv.transform(test_data['review'])\n",
    "\n",
    "# Save the fitted vectorizer for later use\n",
    "joblib.dump(tv, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Train and save your model (replace this with your actual training code)\n",
    "# Assuming you have a SentimentAnalysisModel class with fit_vectorizer and fit_model methods\n",
    "# sentiment_model = SentimentAnalysisModel()\n",
    "# sentiment_model.fit_vectorizer(tv_train_reviews)\n",
    "# sentiment_model.fit_model(your_training_labels)\n",
    "# joblib.dump(sentiment_model, 'your_model.pkl')\n",
    "\n",
    "# Save the trained model\n",
    "# joblib.dump(sentiment_model, 'your_model.pkl')\n",
    "\n",
    "# In a different notebook or script, you can load the vectorizer and model like this:\n",
    "# loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "# loaded_model = joblib.load('your_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62b2d947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your_model.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'data' is your sampled dataset\n",
    "sample_size = 20000\n",
    "random_seed = 42\n",
    "data = df.sample(n=sample_size, random_state=random_seed)\n",
    "\n",
    "# Tokenization and preprocessing functions\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Your preprocessing steps here\n",
    "    # ...\n",
    "\n",
    "    # Assuming 'text' is preprocessed\n",
    "    return text\n",
    "\n",
    "# Preprocess the entire dataset\n",
    "data['review'] = data['review'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = 14000\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "\n",
    "# Initialize and fit the TF-IDF vectorizer\n",
    "tv = TfidfVectorizer(min_df=0, max_df=1, use_idf=True, ngram_range=(1, 3))\n",
    "tv_train_reviews = tv.fit_transform(train_data['review'])\n",
    "tv_test_reviews = tv.transform(test_data['review'])\n",
    "\n",
    "# Save the fitted vectorizer for later use\n",
    "joblib.dump(tv, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Train and save your model (replace this with your actual training code)\n",
    "# ...\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(train_sentiments, 'your_model.pkl')\n",
    "\n",
    "# In a different notebook or script, you can load the vectorizer and model like this:\n",
    "# loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "# loaded_model = joblib.load('your_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6888e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
